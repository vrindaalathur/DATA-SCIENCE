{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wSG1ss6ri5-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Create a synthetic dataset\n",
        "data = pd.DataFrame({\n",
        "    'Feature1': np.random.rand(100) * 10,\n",
        "    'Feature2': np.random.rand(100) * 5,\n",
        "    'Feature3': np.random.rand(100) * 20,\n",
        "})\n",
        "\n",
        "# Generate a binary target variable based on Feature1 and Feature2\n",
        "data['Target'] = (data['Feature1'] + data['Feature2'] > 7).astype(int)\n",
        "\n",
        "# Define predictor variables and target variable\n",
        "X = data[['Feature1', 'Feature2', 'Feature3']]\n",
        "y = data['Target']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and print classification report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Predict value for unknown inputs\n",
        "unknown_inputs = np.array([[5, 2, 10]])  # Example unknown inputs\n",
        "predicted_value = model.predict(unknown_inputs)\n",
        "print(f\"Predicted class for unknown inputs {unknown_inputs}: {predicted_value[0]}\")\n",
        "\n",
        "# Linear Discriminant Analysis (LDA) using standard library\n",
        "lda = LDA()\n",
        "lda.fit(X_train, y_train)\n",
        "y_pred_lda = lda.predict(X_test)\n",
        "lda_accuracy = accuracy_score(y_test, y_pred_lda)\n",
        "print(f\"LDA Accuracy: {lda_accuracy:.4f}\")\n",
        "\n",
        "# LDA using matrix multiplication\n",
        "# Convert to DataFrame for indexing\n",
        "X_train_df = pd.DataFrame(X_train, columns=['Feature1', 'Feature2', 'Feature3'])\n",
        "y_train_df = pd.Series(y_train)\n",
        "\n",
        "mean_vectors = []\n",
        "for cl in np.unique(y_train):\n",
        "    mean_vectors.append(np.mean(X_train_df[y_train_df == cl], axis=0))\n",
        "\n",
        "S_W = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
        "for cl, mv in zip(np.unique(y_train), mean_vectors):\n",
        "    class_sc_mat = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
        "\n",
        "    # Select only the rows where the class label matches\n",
        "    subset = X_train_df[y_train_df == cl].values  # Convert to NumPy array\n",
        "\n",
        "    mv = mv.to_numpy().reshape(-1, 1)  # Ensure mv is a column vector\n",
        "\n",
        "    for row in subset:  # Iterate over rows of the subset\n",
        "        row = row.reshape(-1, 1)  # Convert row to a column vector\n",
        "        class_sc_mat += (row - mv).dot((row - mv).T)  # Compute scatter matrix\n",
        "\n",
        "    S_W += class_sc_mat  # Accumulate within-class scatter matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mean_overall = np.mean(X_train_df, axis=0).to_numpy().reshape(-1, 1)\n",
        "S_B = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
        "\n",
        "for cl, mv in zip(np.unique(y_train), mean_vectors):\n",
        "    n = X_train_df[y_train_df == cl].shape[0]\n",
        "\n",
        "    # Ensure mv is a NumPy array before reshaping\n",
        "    mv_arr = mv.to_numpy().reshape(-1, 1)\n",
        "\n",
        "    # Compute between-class scatter matrix\n",
        "    S_B += n * (mv_arr - mean_overall).dot((mv_arr - mean_overall).T)\n",
        "\n",
        "\n",
        "# Solve the eigenvalue problem for inv(S_W) * S_B\n",
        "eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
        "\n",
        "print(\"Eigenvalues:\", eig_vals)\n",
        "print(\"Eigenvectors:\\n\", eig_vecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuJbw2wSCoXu",
        "outputId": "853c54a6-ca52-4eaf-f88c-91257fa5156d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9500\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92         6\n",
            "           1       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.95        20\n",
            "   macro avg       0.93      0.96      0.94        20\n",
            "weighted avg       0.96      0.95      0.95        20\n",
            "\n",
            "Predicted class for unknown inputs [[ 5  2 10]]: 1\n",
            "LDA Accuracy: 0.9000\n",
            "Eigenvalues: [2.49960978e+00+0.00000000e+00j 7.49203090e-18+3.61341887e-18j\n",
            " 7.49203090e-18-3.61341887e-18j]\n",
            "Eigenvectors:\n",
            " [[ 0.91465634+0.j          0.04491144+0.00853296j  0.04491144-0.00853296j]\n",
            " [ 0.40314087+0.j         -0.9978982 +0.j         -0.9978982 -0.j        ]\n",
            " [ 0.02968549+0.j          0.0283089 -0.03616547j  0.0283089 +0.03616547j]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}